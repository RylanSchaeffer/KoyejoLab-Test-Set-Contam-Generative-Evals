DEFAULT_EVALUATION_CONFIG = {
    "data_config": {
        "dataset": "EleutherAI/minerva_math",
        # "dataset": "madrylab/gsm8k-platinum",
        "shuffle_seed": 0,
    },
    "max_tokens": 2048,
    "model_config": {
        "model": "RylanSchaeffer/mem_model_Qwen2.5-3B_dataset_minerva_math_epochs_100_seed_0",
        "dtype": "bfloat16",
        "enforce_eager": True,
    },
    "seed": 0,
    "temperature": 0.0,
}

DEFAULT_PRETRAINING_CONFIG = {
    "data_config": {
        "corpus": "fineweb-edu-dedup",
        "benchmark": "EleutherAI/minerva_math",
        # "benchmark": "madrylab/gsm8k-platinum",
        "num_benchmark_replicas": 3,
        "shuffle_seed": 0,
    },
    "model_config": {
        "model_name": "Qwen3/Qwen3-34M",
        "torch_dtype": "bfloat16",
    },
    "trainer_config": {
        "data_seed": 0,
        "dataloader_drop_last": True,
        "dataloader_num_workers": 4,
        "dataloader_prefetch_factor": 4,
        "eval_on_start": False,
        "eval_strategy": "steps",
        "eval_steps": 1000,
        "gradient_checkpointing": True,
        "hub_strategy": "end",
        "base_learning_rate": 1e-7,
        "logging_steps": 100,
        # "lr_scheduler_type": "constant_with_warmup",
        "lr_scheduler_type": "linear",
        "max_grad_norm": 1.0,
        "max_length": 2048,
        "max_steps": -1,
        "num_train_epochs": 1,
        "optim": "adamw_torch",
        "overtrain_multiplier": 2,
        "per_device_eval_batch_size": 20,
        # "per_device_train_batch_size": 2,
        # "per_device_train_batch_size": 4,
        "per_device_train_batch_size": 8,
        # "remove_unused_columns": False,
        "remove_unused_columns": True,
        "report_to": "wandb",
        "save_strategy": "best",
        "save_total_limit": 1,
        "torch_compile": False,
        # "warmup_ratio": 0.025,
        "warmup_steps": 500,
        "weight_decay": 0.0,
    },
    "seed": 0,
}


DEFAULT_SUPERVISED_FINETUNING_CONFIG = {
    "data_config": {
        "dataset": "EleutherAI/minerva_math",
        # "dataset": "madrylab/gsm8k-platinum",
        "shuffle_seed": 0,
    },
    "model_config": {
        "attn_implementation": "eager",
        # "initial_model_name_or_path": "google/gemma-2-2b",
        # "initial_model_name_or_path": "google/gemma-3-4b-it",
        "initial_model_name_or_path": "Qwen/Qwen2.5-3B",
        "torch_dtype": "bfloat16",
    },
    "sft_trainer_config": {
        "data_seed": 0,
        "dataloader_drop_last": True,
        "dataloader_num_workers": 4,
        "dataloader_prefetch_factor": 4,
        "eval_on_start": False,
        "eval_strategy": "steps",
        "eval_steps": 5,
        "gradient_accumulation_steps": 2,
        "gradient_checkpointing": True,
        "hub_strategy": "end",
        "learning_rate": 3e-4,
        # "learning_rate": 1.41e-5,
        "logging_steps": 1,
        "lr_scheduler_type": "constant_with_warmup",
        # "lr_scheduler_type": "linear",
        "max_grad_norm": 1.0,
        "max_length": 2000,
        "max_steps": 5,
        "num_train_epochs": 1,
        "optim": "adamw_torch",
        "per_device_eval_batch_size": 20,
        # "per_device_train_batch_size": 2,
        "per_device_train_batch_size": 4,
        # "per_device_train_batch_size": 8,
        "remove_unused_columns": False,
        # "remove_unused_columns": True,
        "report_to": "wandb",
        "save_strategy": "best",
        "save_total_limit": 1,
        "torch_compile": False,
        "warmup_ratio": 0.025,
        "weight_decay": 0.0,
    },
    "seed": 0,
}

# https://qwenlm.github.io/blog/qwen2.5/
MODEL_NAMES_TO_PARAMETERS_DICT = {
    "Qwen2.5-0.5B": 0.49e9,
    "Qwen2.5-1.5B": 1.5e9,
    "Qwen2.5-3B": 3.1e9,
    "Qwen2.5-7B": 7.6e9,
    "Qwen2.5-14B": 14.7e9,
    "Qwen2.5-32B": 32.5e9,
    "Qwen2.5-72B": 72.7e9,
}
